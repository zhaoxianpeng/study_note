---
typora-copy-images-to: ./
---

# 神经网络



## 前言

![神经网络](./神经网络.png)

符号解释

| 符号                | 维度                                                     | 描述                                                         |
| ------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| $n$                 | $\mathbb{R}$                                             | 训练样本个数                                                 |
| $m$                 | $\mathbb{R}$                                             | 每个样本的特征个数                                           |
| $u$                 | $\mathbb{R}$                                             | 输出值个数                                                   |
| $x_{i,j}$           | $\mathbb{R}$                                             | 表示第$i^{th}$个输入样本的第$j^{th}$维特征的输入数据         |
| $x_{i}$             | $\mathbb{R}^{m \times 1}$                                | 表示第$i^{th}$个输入样本的所有m维特征向量                    |
| $X$                 | $\mathbb{R}^{m\times n}$                                 | 表示所有$n$个样本，每个样本有$m$个特征                       |
| $w_{s,t}^{(l)}$     | $\mathbb{R}$                                             | 表示从第$(l-1)^{th}$层的第$s^{th}$个神经元到第$l^{th}$层的$t^{th}$个神经元的权重； |
| $\left | l\right |$ | $\mathbb{R}$                                             | 表示第$l^{th}$层神经元个数；                                 |
| $W^{(l)}$           | $\mathbb{R}^{\left | l-1 \right |\times \left|l\right|}$ | 表示从第$(l-1)^{th}$层到$l^{th}$层映射的权重矩阵;            |
| $f$                 | $\mathbb{R} \rightarrow \mathbb{R}$                      | 激活函数                                                     |
| $z_{i,j}^{(l)}$     | $\mathbb{R}$                                             | 表示输入为第$i^{th}$个样本时，第$l^{th}$层的第$j^{th}$个神经元未激活的值，它是由第$(l-1)^{th}$层的输出经过$W^{(l)}$矩阵加权求和之后的结果。 $z_{i,j}^{(l)} = \sum_{k}^{\left|l-1\right|}a_{i,k}^{(l-1)} \cdot w_{k,j}^{(l)}$ |
| $z_{i}^{(l)}$       | $\mathbb{R}^{\left|l\right| \times 1}$                   | 表示输入为第$i^{th}$个样本时，第$l^{th}$层的$\left|l\right|$个神经元的未激活值组成的向量 |
| $Z^{(l)}$           | $\mathbb{R}^{\left|l\right|\times n}$                    | 表示$n$个样本全部输入时，第$l^{th}$层的n个样本，每个样本$\left|l\right|$个神经元未激活值组成的矩阵 |
| $a_{i,j}^{(l)}$     | $\mathbb{R}$                                             | 表示输入为第$i^{th}$个样本时，第$l^{th}$层的第$j^{th}$个神经元的输出，它是由$z_{i,j}^{(l)}$经过激活函数$f$映射而来 |
| $a_{i}^{(l)}$       | $\mathbb{R}^{\left|l\right| \times 1}$                   | 表示输入为第$i^{th}$个样本时，第$l^{th}$层的$\left|l\right|$个神经元的输出向量 |
| $A^{(l)}$           | $\mathbb{R}^{\left|l\right|\times n}$                    | 表示$n$个样本全部输入时，第$l^{th}$层的n个样本，每个样本$\left|l\right|$个神经元的输出组成的矩阵 |
| $\hat{y}_{i,j}$     | $\mathbb{R}$                                             | 表示输入为第$i^{th}$个样本时，输出层的第$j^{th}$个神经元的输出，也是整个模型的第$j^{th}$个的输出 |
| $\hat{y}_{i}$       | $\mathbb{R}^{u \times 1}$                                | 表述输入为第$i^{th}$个样本时，输出层的$u$个神经元的输出向量  |
| $\hat{Y}$           | $\mathbb{R}^{u \times n}$                                | 表示$n$个样本全部输入时，输出层的n个样本输出，每个样本$u$个输出组成的矩阵 |
| $y_{i,j}$           | $\mathbb{R}$                                             | 表示第$i^{th}$个输入样本的第$j^{th}$个实际输出值             |
| $y_i$               | $\mathbb{R}^{u \times 1}$                                | 表述第$i^{th}$个样本输出的$u$个实际输出向量                  |
| $Y$                 | $\mathbb{R}^{u \times n}$                                | 表示所有n个样本的的实际输出，每个样本$u$个实际输出组成的矩阵 |

输入为一个样本时

常用公式


$$
z_{i,j}^{(l)} = \sum_{k}^{\left|l-1\right|}a_{i,k}^{(l-1)} \cdot w_{k,j}^{(l)}
$$

经过激活函数之后
$$
a_{i,j}^{(l)} = f(z_{i,j}^{(l)})
$$


写成向量形式
$$
z_i^{(l)} = \left(W^{(l)}\right)^Ta_{i}^{(l-1)}
$$
经过激活函数
$$
a_{i}^{(l)} = f(z_{i}^{(l)})
$$


输入为n个样本时
$$
Z^{(l)}= \left(W^{(l)}\right)^TA^{(l-1)}
$$






## 前向传播

假设$A^{(0)}$为输入层，即为输入矩阵$X$维度为：$m\times n$；所有的$W$初始化为随机值；

其中，$W^{(1)}$的维度为$m \times r$，其中$r$为第二层的神经元个数。应用公式(5)可以求出$Z^{(1)}$,维度为$r\times n$。然后对每个元素应用激活函数可以求出$A^{(1)}$，在继续应用公式(5)可以求出$Z^{(2)}$，依次递推可以求出神经网络中所有神经元的值。



##　损失函数和代价函数

本文针对单个样本的预测值与真实值之间的误差使用损失函数描述；对于全部n个样本的误差采用代价函数来描述。

常用的误差函数有均方误差，交叉熵损失，合页损失，对数损失等，不管具体用什么损失函数，我们定义我们的损失函数为$loss(\hat{y}_{i,j},y_{i,j})$，这里该函数可以是任何合理的损失函数，他的两个参数都为标量，它度量了预测值与实际值的差距。

第$i^{th}$个样本的损失函数：
$$
L(\hat{y}_i, y_i) =  \sum_{j=1}^u loss(\hat{y}_{i,j}, y_{i,j})
$$

代价函数为：
$$
C(\hat{Y}, Y) = \frac{1}{n} \sum_{i=1}^{n}L(\hat{y}_i, y_i) = \sum_{i=1}^n\left[ \sum_{j=1}^u loss(\hat{y}_{i,j}, y_{i,j}) \right]
$$
